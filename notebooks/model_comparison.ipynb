{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom452/.conda/envs/eyerub-det/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import scipy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.datasets.supervised_dataset import SupervisedDataset\n",
    "from src.models.label_encoder import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "features = ['accelerometerAccelerationX(G)', \n",
    "            'accelerometerAccelerationY(G)',\n",
    "            'accelerometerAccelerationZ(G)', \n",
    "            'motionYaw(rad)', \n",
    "            'motionRoll(rad)',\n",
    "            'motionPitch(rad)', \n",
    "            'motionRotationRateX(rad/s)',\n",
    "            'motionRotationRateY(rad/s)', \n",
    "            'motionRotationRateZ(rad/s)',\n",
    "            'motionUserAccelerationX(G)', \n",
    "            'motionUserAccelerationY(G)',\n",
    "            'motionUserAccelerationZ(G)', \n",
    "            'motionQuaternionX(R)',\n",
    "            'motionQuaternionY(R)', \n",
    "            'motionQuaternionZ(R)', \n",
    "            'motionQuaternionW(R)',\n",
    "            'motionGravityX(G)', \n",
    "            'motionGravityY(G)', \n",
    "            'motionGravityZ(G)'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(dataset):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for sequence, label in dataset:\n",
    "        # Compute the statistics for each column\n",
    "        _min = np.min(sequence.numpy(), axis=0)\n",
    "        _max = np.max(sequence.numpy(), axis=0)\n",
    "        _std = np.std(sequence.numpy(), axis=0)\n",
    "        _mean = np.mean(sequence.numpy(), axis=0)\n",
    "        _skew = skew(sequence.numpy(), axis=0)\n",
    "        _kurtosis = kurtosis(sequence.numpy(), axis=0)\n",
    "        feats = np.concatenate((_min, _max, _std, _mean, _skew, _kurtosis)).reshape(1, -1)\n",
    "        X.append(feats)\n",
    "        y.append(label.item())\n",
    "    \n",
    "    return np.concatenate(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, probs):\n",
    "    f1 = f1_score(y_true, y_pred, average = 'macro')\n",
    "    roc_auc_ovr = roc_auc_score(y_true, probs, multi_class='ovr')\n",
    "    roc_auc_ovo = roc_auc_score(y_true, probs, multi_class='ovo')\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(probs.shape[1]):\n",
    "        fpr[i], tpr[i], _ = roc_curve(label_binarize(y_test, classes=[0, 1, 2, 3, 4])[:, i], probs[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    return f1, roc_auc_ovr, roc_auc_ovo, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 141\n",
    "max_depth = 16\n",
    "seed = 42\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=n_estimators, \n",
    "                                    max_depth=max_depth, \n",
    "                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = make_pipeline(StandardScaler(), SVC(gamma='auto'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 13792.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1: Train:  ['user50', 'user59', 'user57', 'user53', 'user55', 'user56'] Val:  ['user54', 'user52', 'user60', 'user58'] Test:  ['user51']\n",
      "Split 2: Train:  ['user50', 'user54', 'user51', 'user55', 'user60', 'user58'] Val:  ['user53', 'user56', 'user57', 'user59'] Test:  ['user52']\n",
      "Split 3: Train:  ['user50', 'user54', 'user51', 'user55', 'user60', 'user58'] Val:  ['user57', 'user59', 'user56', 'user52'] Test:  ['user53']\n",
      "Split 4: Train:  ['user50', 'user59', 'user58', 'user60', 'user53', 'user51'] Val:  ['user56', 'user55', 'user57', 'user52'] Test:  ['user54']\n",
      "Split 5: Train:  ['user50', 'user52', 'user58', 'user57', 'user51', 'user53'] Val:  ['user56', 'user60', 'user59', 'user54'] Test:  ['user55']\n",
      "Split 6: Train:  ['user50', 'user53', 'user55', 'user60', 'user54', 'user51'] Val:  ['user59', 'user57', 'user58', 'user52'] Test:  ['user56']\n",
      "Split 7: Train:  ['user50', 'user53', 'user54', 'user51', 'user60', 'user58'] Val:  ['user55', 'user59', 'user52', 'user56'] Test:  ['user57']\n",
      "Split 8: Train:  ['user50', 'user56', 'user57', 'user59', 'user51', 'user54'] Val:  ['user55', 'user53', 'user60', 'user52'] Test:  ['user58']\n",
      "Split 9: Train:  ['user50', 'user54', 'user51', 'user58', 'user53', 'user60'] Val:  ['user55', 'user57', 'user56', 'user52'] Test:  ['user59']\n",
      "Split 10: Train:  ['user50', 'user54', 'user59', 'user51', 'user58', 'user53'] Val:  ['user52', 'user55', 'user56', 'user57'] Test:  ['user60']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def user_splits(seed=42):\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # List of users excluding user50 since it will always be in the training set\n",
    "    users = [\"user51\", \"user52\", \"user53\", \"user54\", \"user55\", \"user56\", \"user57\", \"user58\", \"user59\", \"user60\"]\n",
    "    splits = []\n",
    "    \n",
    "    # Loop over each user to be used as the test user\n",
    "    for test_user in users:\n",
    "        remaining_users = [user for user in users if user != test_user]\n",
    "        # Shuffle the remaining users for random splits\n",
    "        random.shuffle(remaining_users)\n",
    "        # First 6 users (including user50) for training, next 4 for validation\n",
    "        train_users = ['user50'] + remaining_users[:5]\n",
    "        val_users = remaining_users[5:9]\n",
    "        splits.append((train_users, val_users, [test_user]))\n",
    "    return splits\n",
    "\n",
    "#os.mkdir(\"loocv\")\n",
    "for i, (train_users, val_users, test_users) in tqdm(enumerate(user_splits(seed=0))):\n",
    "    print(f\"Split {i+1}: Train: \", train_users, \"Val: \", val_users, \"Test: \", test_users)\n",
    "    save_split = False\n",
    "    if save_split:\n",
    "        os.mkdir(f\"loocv/split_{i+1}\")\n",
    "        with open(f\"loocv/split_{i+1}/users_train.txt\", \"w+\") as f:\n",
    "            for user in train_users:\n",
    "                f.write(f\"{user}\\n\")\n",
    "\n",
    "        with open(f\"loocv/split_{i+1}/users_val.txt\", \"w+\") as f:\n",
    "            for user in val_users:\n",
    "                f.write(f\"{user}\\n\")\n",
    "\n",
    "        with open(f\"loocv/split_{i+1}/users_test.txt\", \"w+\") as f:\n",
    "            for user in test_users:\n",
    "                f.write(f\"{user}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:17<00:00, 13.71s/it]\n"
     ]
    }
   ],
   "source": [
    "knn_results = {'f1': [], 'auc_ovr': [], 'auc_ovo': [], 'auc': []}\n",
    "random_forest_results = {'f1': [], 'auc_ovr': [], 'auc_ovo': [], 'auc': []}\n",
    "svm_results = {'f1': [], 'auc_ovr': [], 'auc_ovo': [], 'auc': []}\n",
    "\n",
    "for train_users, _, test_users in tqdm(user_splits(seed=0)):\n",
    "    # Load data:\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_data = SupervisedDataset(data_dir, train_users, features, label_encoder, normalize=False)\n",
    "    test_data = SupervisedDataset(data_dir, test_users, features, label_encoder, normalize=False)\n",
    "\n",
    "    X_train, y_train = compute_features(train_data)\n",
    "    X_test, y_test = compute_features(test_data)\n",
    "\n",
    "    # KNN:\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    probs = knn.predict_proba(X_test)\n",
    "    f1, roc_auc_ovr, roc_auc_ovo, roc_auc = evaluate(y_test, y_pred, probs)\n",
    "    knn_results['f1'].append(f1)\n",
    "    knn_results['auc_ovr'].append(roc_auc_ovr)\n",
    "    knn_results['auc_ovo'].append(roc_auc_ovo)\n",
    "    knn_results['auc'].append(roc_auc)\n",
    "    \n",
    "\n",
    "    # Random Forest:\n",
    "    random_forest.fit(X_train, y_train)\n",
    "    y_pred = random_forest.predict(X_test)\n",
    "    probs = random_forest.predict_proba(X_test)\n",
    "    f1, roc_auc_ovr, roc_auc_ovo, roc_auc = evaluate(y_test, y_pred, probs)\n",
    "    random_forest_results['f1'].append(f1)\n",
    "    random_forest_results['auc_ovr'].append(roc_auc_ovr)\n",
    "    random_forest_results['auc_ovo'].append(roc_auc_ovo)\n",
    "    random_forest_results['auc'].append(roc_auc)\n",
    "\n",
    "    # SVM:\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    probs = svc.decision_function(X_test)\n",
    "    probs = softmax(probs, axis=1)\n",
    "    f1, roc_auc_ovr, roc_auc_ovo, roc_auc = evaluate(y_test, y_pred, probs)\n",
    "    svm_results['f1'].append(f1)\n",
    "    svm_results['auc_ovr'].append(roc_auc_ovr)\n",
    "    svm_results['auc_ovo'].append(roc_auc_ovo)\n",
    "    svm_results['auc'].append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0_results = {'f1': [], 'auc_ovr': [], 'auc_ovo': []}\n",
    "v1_results = {'f1': [], 'auc_ovr': [], 'auc_ovo': []}\n",
    "v2_results = {'f1': [], 'auc_ovr': [], 'auc_ovo': []}\n",
    "v3_results = {'f1': [], 'auc_ovr': [], 'auc_ovo': []}\n",
    "\n",
    "for split in range(1, 11):\n",
    "    # Transformer v0:  \n",
    "    with open(f'../out/loocv/split_{split}/v0_pretrained/results_test.json') as f:\n",
    "        results = json.load(f)\n",
    "        v0_results['f1'].append(results['f1'])\n",
    "        v0_results['auc_ovr'].append(results['auc_ovr'])\n",
    "        v0_results['auc_ovo'].append(results['auc_ovo'])\n",
    "        \n",
    "    # Transformer v1:  \n",
    "    with open(f'../out/loocv/split_{split}/v1_pretrained/results_test.json') as f:\n",
    "        results = json.load(f)\n",
    "        v1_results['f1'].append(results['f1'])\n",
    "        v1_results['auc_ovr'].append(results['auc_ovr'])\n",
    "        v1_results['auc_ovo'].append(results['auc_ovo'])\n",
    "        \n",
    "    # Transformer v2:  \n",
    "    with open(f'../out/loocv/split_{split}/v2_pretrained/results_test.json') as f:\n",
    "        results = json.load(f)\n",
    "        v2_results['f1'].append(results['f1'])\n",
    "        v2_results['auc_ovr'].append(results['auc_ovr'])\n",
    "        v2_results['auc_ovo'].append(results['auc_ovo'])\n",
    "    \n",
    "    # Transformer v3:  \n",
    "    with open(f'../out/loocv/split_{split}/v3_pretrained/results_test.json') as f:\n",
    "        results = json.load(f)\n",
    "        v3_results['f1'].append(results['f1'])\n",
    "        v3_results['auc_ovr'].append(results['auc_ovr'])\n",
    "        v3_results['auc_ovo'].append(results['auc_ovo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h\n",
    "\n",
    "def print_results(method_name, results):\n",
    "    mean, low, high = mean_confidence_interval(results['f1'])\n",
    "    print(\"{} F1: {:.2f} ({:.2f}-{:.2f})\".format(method_name, mean, low, high))\n",
    "\n",
    "    mean, low, high = mean_confidence_interval(results['auc_ovr'])\n",
    "    print(\"{} AUC (OVR): {:.2f} ({:.2f}-{:.2f})\".format(method_name, mean, low, high))\n",
    "\n",
    "    mean, low, high = mean_confidence_interval(results['auc_ovo'])\n",
    "    print(\"{} AUC (OV0): {:.2f} ({:.2f}-{:.2f})\".format(method_name, mean, low, high))\n",
    "    \n",
    "    mean, low, high = mean_confidence_interval([res[1] for res in results['auc']])\n",
    "    print(\"{} AUC (1): {:.2f} ({:.2f}-{:.2f})\".format(method_name, mean, low, high))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN F1: 0.42 (0.37-0.48)\n",
      "KNN AUC (OVR): 0.72 (0.68-0.77)\n",
      "KNN AUC (OV0): 0.72 (0.68-0.77)\n",
      "KNN AUC (1): 0.66 (0.62-0.70)\n"
     ]
    }
   ],
   "source": [
    "print_results('KNN', knn_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest F1: 0.52 (0.43-0.61)\n",
      "Random Forest AUC (OVR): 0.85 (0.82-0.88)\n",
      "Random Forest AUC (OV0): 0.85 (0.82-0.88)\n",
      "Random Forest AUC (1): 0.81 (0.76-0.85)\n"
     ]
    }
   ],
   "source": [
    "print_results('Random Forest', random_forest_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM F1: 0.50 (0.42-0.57)\n",
      "SVM AUC (OVR): 0.83 (0.80-0.87)\n",
      "SVM AUC (OV0): 0.83 (0.80-0.87)\n",
      "SVM AUC (1): 0.77 (0.72-0.82)\n"
     ]
    }
   ],
   "source": [
    "print_results('SVM', svm_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'v3_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/n/groups/patel/tom/EyeRub-Det/notebooks/model_comparison.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://127.0.0.1:50233/n/groups/patel/tom/EyeRub-Det/notebooks/model_comparison.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m print_results(\u001b[39m'\u001b[39m\u001b[39mTransformer\u001b[39m\u001b[39m'\u001b[39m, v3_results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'v3_results' is not defined"
     ]
    }
   ],
   "source": [
    "print_results('Transformer', v3_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1\n",
      "0.50\n",
      "0.53\n",
      "0.48\n",
      "0.41\n",
      "0.57\n",
      "0.31\n",
      "0.39\n",
      "0.68\n",
      "0.64\n",
      "0.67\n",
      "\n",
      "auc (1)\n",
      "0.81\n",
      "0.78\n",
      "0.82\n",
      "0.66\n",
      "0.83\n",
      "0.84\n",
      "0.78\n",
      "0.87\n",
      "0.87\n",
      "0.81\n"
     ]
    }
   ],
   "source": [
    "print('f1')\n",
    "for x in random_forest_results['f1']:\n",
    "    print('{:.2f}'.format(x))\n",
    "    \n",
    "print('\\nauc (1)')\n",
    "for x in [res[1] for res in random_forest_results['auc']]:\n",
    "    print('{:.2f}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfi_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
